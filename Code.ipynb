{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DATE      SP500  NASDAQ.AAL  NASDAQ.AAPL  NASDAQ.ADBE  NASDAQ.ADI  \\\n",
      "0  1491226200  2363.6101     42.3300     143.6800     129.6300      82.040   \n",
      "1  1491226260  2364.1001     42.3600     143.7000     130.3200      82.080   \n",
      "2  1491226320  2362.6799     42.3100     143.6901     130.2250      82.030   \n",
      "3  1491226380  2364.3101     42.3700     143.6400     130.0729      82.000   \n",
      "4  1491226440  2364.8501     42.5378     143.6600     129.8800      82.035   \n",
      "\n",
      "   NASDAQ.ADP  NASDAQ.ADSK  NASDAQ.AKAM  NASDAQ.ALXN  ...  NYSE.WYN  NYSE.XEC  \\\n",
      "0    102.2300      85.2200       59.760       121.52  ...    84.370   119.035   \n",
      "1    102.1400      85.6500       59.840       121.48  ...    84.370   119.035   \n",
      "2    102.2125      85.5100       59.795       121.93  ...    84.585   119.260   \n",
      "3    102.1400      85.4872       59.620       121.44  ...    84.460   119.260   \n",
      "4    102.0600      85.7001       59.620       121.60  ...    84.470   119.610   \n",
      "\n",
      "   NYSE.XEL  NYSE.XL  NYSE.XOM  NYSE.XRX  NYSE.XYL  NYSE.YUM  NYSE.ZBH  \\\n",
      "0     44.40    39.88     82.03      7.36     50.22     63.86   122.000   \n",
      "1     44.11    39.88     82.03      7.38     50.22     63.74   121.770   \n",
      "2     44.09    39.98     82.02      7.36     50.12     63.75   121.700   \n",
      "3     44.25    39.99     82.02      7.35     50.16     63.88   121.700   \n",
      "4     44.11    39.96     82.03      7.36     50.20     63.91   121.695   \n",
      "\n",
      "   NYSE.ZTS  \n",
      "0    53.350  \n",
      "1    53.350  \n",
      "2    53.365  \n",
      "3    53.380  \n",
      "4    53.240  \n",
      "\n",
      "[5 rows x 502 columns]\n"
     ]
    }
   ],
   "source": [
    "# import data from the csv file\n",
    "data = pd.read_csv('data_stocks.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41266\n",
      "501\n"
     ]
    }
   ],
   "source": [
    "# drop the date from the dataset loaded \n",
    "data = data.drop(['DATE'], 1)\n",
    "\n",
    "#Taking the dimensions of the dataset\n",
    "n = data.shape[0]\n",
    "p = data.shape[1]\n",
    "\n",
    "print(n)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data a numpy array\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "33012\n",
      "33012\n",
      "41266\n",
      "33012\n",
      "501\n",
      "[[2363.6101   42.33    143.68    129.63     82.04  ]\n",
      " [2364.1001   42.36    143.7     130.32     82.08  ]\n",
      " [2362.6799   42.31    143.6901  130.225    82.03  ]\n",
      " [2364.3101   42.37    143.64    130.0729   82.    ]\n",
      " [2364.8501   42.5378  143.66    129.88     82.035 ]]\n"
     ]
    }
   ],
   "source": [
    "# training and testing data\n",
    "train_start = 0\n",
    "train_end = int(np.floor(0.8*n))\n",
    "test_start = train_end\n",
    "test_end = n\n",
    "\n",
    "print(train_start)\n",
    "print(train_end)\n",
    "print(test_start)\n",
    "print(test_end)\n",
    "\n",
    "data_train = data[np.arange(train_start, train_end), :]\n",
    "data_test = data[np.arange(test_start, test_end), :]\n",
    "\n",
    "print(data_train.shape[0])\n",
    "print(data_train.shape[1])\n",
    "print(data_train[0:5,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2242253  0.10993038 0.18116315 0.06281066 0.4629156 ]\n",
      " [0.2274127  0.11212898 0.18219249 0.09399006 0.46547315]\n",
      " [0.21817444 0.10846464 0.18168296 0.08969724 0.46227621]\n",
      " [0.22877873 0.11286185 0.17910448 0.08282422 0.46035806]\n",
      " [0.23229138 0.1251594  0.18013381 0.07410755 0.46259591]]\n"
     ]
    }
   ],
   "source": [
    "# scale data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data_train)\n",
    "data_train = scaler.transform(data_train)\n",
    "data_test = scaler.transform(data_test)\n",
    "print(data_train[0:5,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 42.33   143.68   129.63   ...  63.86   122.      53.35  ]\n",
      " [ 42.36   143.7    130.32   ...  63.74   121.77    53.35  ]\n",
      " [ 42.31   143.6901 130.225  ...  63.75   121.7     53.365 ]\n",
      " ...\n",
      " [ 50.54   158.0143 146.59   ...  76.37   117.8688  61.535 ]\n",
      " [ 50.52   157.8701 146.6    ...  76.35   117.91    61.52  ]\n",
      " [ 50.52   157.8    146.53   ...  76.335  117.83    61.54  ]]\n",
      "[2363.6101 2364.1001 2362.6799 ... 2475.05   2474.8601 2474.6201]\n"
     ]
    }
   ],
   "source": [
    "# building X & Y from our present dataset\n",
    "X_train = data_train[:, 1:]\n",
    "y_train = data_train[:, 0]\n",
    "X_test = data_test[:, 1:]\n",
    "y_test = data_test[:, 0]\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture parameters\n",
    "n_stocks = 500 # No. of Columns\n",
    "n_neurons_1 = 1024 \n",
    "n_neurons_2 = 512\n",
    "n_neurons_3 = 256\n",
    "n_neurons_4 = 128\n",
    "n_target = 1\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, n_stocks])\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "\n",
    "# Initializers\n",
    "sigma = 1\n",
    "weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "bias_initializer = tf.zeros_initializer()\n",
    "\n",
    "# Layer 1: Variables for hidden weights and biases\n",
    "W_hidden_1 = tf.Variable(weight_initializer([n_stocks, n_neurons_1]))\n",
    "bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "\n",
    "# Layer 2: Variables for hidden weights and biases\n",
    "W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "\n",
    "# Layer 3: Variables for hidden weights and biases\n",
    "W_hidden_3 = tf.Variable(weight_initializer([n_neurons_2, n_neurons_3]))\n",
    "bias_hidden_3 = tf.Variable(bias_initializer([n_neurons_3]))\n",
    "\n",
    "# Layer 4: Variables for hidden weights and biases\n",
    "W_hidden_4 = tf.Variable(weight_initializer([n_neurons_3, n_neurons_4]))\n",
    "bias_hidden_4 = tf.Variable(bias_initializer([n_neurons_4]))\n",
    "\n",
    "# Output layer: Variables for output weights and biases\n",
    "W_out = tf.Variable(weight_initializer([n_neurons_4, n_target]))\n",
    "bias_out = tf.Variable(bias_initializer([n_target]))\n",
    "\n",
    "\n",
    "# In[93]:\n",
    "\n",
    "\n",
    "# Hidden layer\n",
    "hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "hidden_3 = tf.nn.relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))\n",
    "hidden_4 = tf.nn.relu(tf.add(tf.matmul(hidden_3, W_hidden_4), bias_hidden_4))\n",
    "\n",
    "# Output layer (must be transposed)\n",
    "out = tf.transpose(tf.add(tf.matmul(hidden_4, W_out), bias_out))\n",
    "\n",
    "\n",
    "# In[94]:\n",
    "\n",
    "\n",
    "# Cost function\n",
    "mse = tf.reduce_mean(tf.squared_difference(out, Y))\n",
    "\n",
    "# Optimizer\n",
    "opt = tf.train.AdamOptimizer().minimize(mse)\n",
    "\n",
    "\n",
    "# In[95]:\n",
    "\n",
    "\n",
    "# Make Session\n",
    "net = tf.Session()\n",
    "\n",
    "# Run initializer\n",
    "net.run(tf.global_variables_initializer())\n",
    "\n",
    "# Setup interactive plot\n",
    "plt.ion()\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "line1, = ax1.plot(y_test)\n",
    "line2, = ax1.plot(y_test*0.5)\n",
    "plt.show()\n",
    "\n",
    "# Number of epochs and batch size\n",
    "epochs = 10\n",
    "batch_size = 256\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    # Shuffle training data\n",
    "    shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "    X_train = X_train[shuffle_indices]\n",
    "    y_train = y_train[shuffle_indices]\n",
    "\n",
    "    # Minibatch training\n",
    "    for i in range(0, len(y_train) // batch_size):\n",
    "        start = i * batch_size\n",
    "        batch_x = X_train[start:start + batch_size]\n",
    "        batch_y = y_train[start:start + batch_size]\n",
    "        # Run optimizer with batch\n",
    "        net.run(opt, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "        # Show progress\n",
    "        if np.mod(i, 5) == 0:\n",
    "            # Prediction\n",
    "            pred = net.run(out, feed_dict={X: X_test})\n",
    "            line2.set_ydata(pred)\n",
    "            plt.title('Epoch ' + str(e) + ', Batch ' + str(i))\n",
    "            file_name = 'epoch_' + str(e) + '_batch_' + str(i) + '.jpg'\n",
    "            plt.savefig(file_name)\n",
    "            plt.pause(0.01)\n",
    "\n",
    "# Print final MSE after Training\n",
    "mse_final = net.run(mse, feed_dict={X: X_test, Y: y_test})\n",
    "print(mse_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
